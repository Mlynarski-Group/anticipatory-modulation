# anticipatory-modulation
Code for the paper "Anticipatory modulation as a unifying principle of sensory coding during active behavior" by Jonathan Gant and Wiktor Mlynarski at the LMU Munich.

# Install instructions
In order to run the code, please ensure Python 3 is installed and install the required packages by running

```
pip install -r requirements.txt
```

# Data availability
The natural video data is available at https://gin.g-node.org/mlynarski/anticipatorymodulation. In order for the data to be properly loaded into the analysis code please place the video data folders (nat_videos and nat_videos_multi_speed) in the data directory.

# Code usage
## Generate results
To generate the Gabor responses to the natural videos run the python scripts in gen_gabor_response. For example,
```
python3 gabor_filter_bank_new_nat_video_matched_rf.py
```

The optimal nonlinearity parameters are determined by running
```
python3 optimize_nonlinearity_gaussian_analytic_fast.py
```
in the folder gen_gabor_response.

The minimal model simulation can be run by executing
```
python3 agent_sim.py
```
while in the minimal_model directory.

The independent components and their responses can be generated by first navigating to the directory fig4 and then running
```
python3 image_patch_ica.py
```
to learn the independent components and then subsequently running
```
python3 gen_ic_filt_resp.py
```
to generate the responses.

## Data analysis
The panels in each figure were generated using the Jupyter notebooks in the respective fig*/ directories.
