{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d60d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script attempts to replicate the results of Mineault et al. showing a decrease in the decoder error during locomotion\n",
    "Author: Jonathan Gant\n",
    "Date: 29.08.2024\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities import calc_entropy\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import os\n",
    "import bottleneck as bn\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# load in the data\n",
    "all_gabor_responses = h5py.File('../results/new_nat_videos_gabor_responses_full_res_more_low_freq_z_score.h5', 'r')\n",
    "\n",
    "# video size\n",
    "resolution_height = 1080\n",
    "resolution_width = 1920\n",
    "\n",
    "# fov\n",
    "horizontal_fov = 92\n",
    "vertical_fov = 61\n",
    "\n",
    "# conversion factor of pixels to degrees\n",
    "horizontal_pixels_per_degree = resolution_width / horizontal_fov\n",
    "vertical_pixels_per_degree = resolution_height / vertical_fov\n",
    "\n",
    "# average of the conversion factors to the nearest integer\n",
    "pixels_per_degree = np.ceil((horizontal_pixels_per_degree + vertical_pixels_per_degree) / 2)\n",
    "print(pixels_per_degree)\n",
    "\n",
    "# data hyperparameters\n",
    "orientation_arr = all_gabor_responses['orientation_arr'][()]\n",
    "phase_arr = all_gabor_responses['phase_arr'][()]\n",
    "position_arr = all_gabor_responses['position_arr'][()]\n",
    "wavelength_arr = all_gabor_responses['wavelength_arr'][()]\n",
    "freq_arr = pixels_per_degree / wavelength_arr\n",
    "filter_size = (resolution_height, resolution_width)\n",
    "print(freq_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bottleneck as bn\n",
    "\n",
    "environments = ['field', 'forest', 'orchard', 'tall_grass', 'pond']\n",
    "\n",
    "stationary_stim_SD = []\n",
    "moving_stim_SD = []\n",
    "stationary_stim = []\n",
    "moving_stim = []\n",
    "\n",
    "fps = 30\n",
    "window_length = np.array([5]) # seconds\n",
    "window_size = window_length * fps\n",
    "print(window_size)\n",
    "num_samples = 1740\n",
    "\n",
    "# get the responses for each environment\n",
    "for i in range(len(window_size)):\n",
    "    stationary_stim_SD_temp = []\n",
    "    moving_stim_SD_temp = []\n",
    "    stationary_stim_temp = []\n",
    "    moving_stim_temp = []\n",
    "    for env_key in environments:\n",
    "        all_gabor_responses_env = all_gabor_responses[env_key]\n",
    "        print(all_gabor_responses_env.keys())\n",
    "        for vid_key in all_gabor_responses_env.keys():\n",
    "            # compute the moving SD\n",
    "            resp_SD = bn.move_std(all_gabor_responses_env[vid_key][()], window=window_size[i], min_count=window_size[i], axis=-1)[:, :, :, :, :num_samples]\n",
    "            if 'stationary' in vid_key:\n",
    "                stationary_stim_SD_temp.append(resp_SD)\n",
    "                stationary_stim_temp.append(all_gabor_responses_env[vid_key][()])\n",
    "            if 'moving' in vid_key and 'free_moving' not in vid_key:\n",
    "                moving_stim_SD_temp.append(resp_SD)\n",
    "                moving_stim_temp.append(all_gabor_responses_env[vid_key][()])\n",
    "    stationary_stim_SD.append(stationary_stim_SD_temp)\n",
    "    moving_stim_SD.append(moving_stim_SD_temp)\n",
    "    stationary_stim.append(stationary_stim_temp)\n",
    "    moving_stim.append(moving_stim_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa29458",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_stim_SD = np.array(stationary_stim_SD)\n",
    "moving_stim_SD = np.array(moving_stim_SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_std_stationary_responses = np.nanmean(stationary_stim_SD[0, :, :, :, :, :, :], axis=(0, -1))\n",
    "windowed_std_moving_responses = np.nanmean(moving_stim_SD[0, :, :, :, :, :, :], axis=(0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15513f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "20/wavelength_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize nonlinearities using lookup table\n",
    "dir_name = 'gaussian_optimization_analytic_fast' # 'all_sigma_more_bins_zscored_data'# 'higher_sigma_for_zscored_data' # 'more_sigma_bins_gaussian_results' # 'even_more_sigma_bins_gaussian_results'\n",
    "\n",
    "MI_arr = np.load(dir_name + '/MI_arr.npy')\n",
    "# stimulus_entropy = np.load(dir_name + '/stimulus_entropy.npy')\n",
    "average_response_arr = np.load(dir_name + '/average_response_arr.npy')\n",
    "\n",
    "# stimulus_bins = np.load(dir_name + '/stimulus_bins.npy') # np.linspace(-30, 30, 200)\n",
    "\n",
    "# Define the range of k and L values for grid search\n",
    "k_arr = np.load(dir_name + '/k_arr.npy') # np.logspace(-2, 2, num_bins) # 5*np.logspace(-2, 0, 100)\n",
    "L_arr = np.load(dir_name + '/L_arr.npy') # np.arange(0.02, 4.02, .02) # np.arange(0.05, 5.05, .05)\n",
    "sigma_arr = np.load(dir_name + '/sigma_arr.npy') # 5*np.logspace(-2, 1, num_bins) # np.logspace(-2, 2, num_bins)\n",
    "\n",
    "# for each sigma compute the optimal parameters for a range of different lambdas\n",
    "lambda_arr = np.arange(0, 2.25, 0.25)\n",
    "optimal_k = np.zeros((len(sigma_arr), len(lambda_arr)))\n",
    "optimal_L = np.zeros((len(sigma_arr), len(lambda_arr)))\n",
    "\n",
    "# import gaussian filter to involve\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "for i, lambda_ in enumerate(lambda_arr):\n",
    "    utility = MI_arr - lambda_ * average_response_arr\n",
    "    print(utility.shape)\n",
    "    # utility = gaussian_filter(utility, sigma=4, axes=(1, 2))\n",
    "    for j, sigma in enumerate(sigma_arr):\n",
    "        optimal_k[j, i] = k_arr[np.unravel_index(np.argmax(utility[j, :, :]), utility[j, :, :].shape)[0]]\n",
    "        optimal_L[j, i] = L_arr[np.unravel_index(np.argmax(utility[j, :, :]), utility[j, :, :].shape)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all orientations and phases and wavelengths and compute the optimal parameters for each\n",
    "optimal_k_arr_moving = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_L_arr_moving = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_k_arr_stationary = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_L_arr_stationary = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "\n",
    "for i, orientation in tqdm(enumerate(orientation_arr)):\n",
    "    print(\"orientation: \" + str(orientation))\n",
    "    for j, phase in enumerate(phase_arr):\n",
    "        for l, wavelength in enumerate(wavelength_arr):\n",
    "            for m, position in enumerate(position_arr):\n",
    "                test_moving_std = windowed_std_moving_responses[i, j, l, m]\n",
    "                test_stationary_std = windowed_std_stationary_responses[i, j, l, m]\n",
    "                for n, lambda_ in enumerate(lambda_arr):\n",
    "                    moving_idx = np.argmin(np.abs(sigma_arr - test_moving_std))\n",
    "                    optimal_k_arr_moving[i, j, l, m, n] = optimal_k[moving_idx, n]\n",
    "                    optimal_L_arr_moving[i, j, l, m, n] = optimal_L[moving_idx, n]\n",
    "                    stationary_idx = np.argmin(np.abs(sigma_arr - test_stationary_std))\n",
    "                    optimal_k_arr_stationary[i, j, l, m, n] = optimal_k[stationary_idx, n]\n",
    "                    optimal_L_arr_stationary[i, j, l, m, n] = optimal_L[stationary_idx, n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea68a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_L_arr_moving[:, :, :, :, 2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fef828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic non-linearity\n",
    "def logistic_func(s, s_0=0, k=1, L=1):\n",
    "    try:\n",
    "        return L / (1 + np.exp(-k * (s - s_0)))\n",
    "    except OverflowError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160bd784-6d73-4be4-8242-c61a6b019779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_moving_entropy_mean(values, binning_scheme, window_length):\n",
    "    moving_entropy = np.zeros(int(len(values)/window_length))\n",
    "    moving_mean = np.zeros(int(len(values)/window_length))\n",
    "    for i, val in enumerate(np.arange(0, len(values), window_length)):\n",
    "        if val % window_length == 0:\n",
    "            windowed_values = values[val:val+window_length]\n",
    "            hist_values, _ = np.histogram(windowed_values, bins=binning_scheme, weights=np.ones_like(windowed_values)/len(windowed_values))\n",
    "            # hist_values += 1e-10\n",
    "            hist_values /= np.sum(hist_values)\n",
    "            # find where hist_values is nonzero\n",
    "            non_zero_val = hist_values > 0\n",
    "            entropy = -np.sum(hist_values[non_zero_val]*np.log2(hist_values[non_zero_val]))\n",
    "            moving_entropy[i] = entropy\n",
    "            moving_mean[i] = np.mean(windowed_values)\n",
    "    return moving_entropy, moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfd44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7acbc-821f-4564-9958-a25b43aae0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a set of stimuli\n",
    "import bottleneck as bn\n",
    "\n",
    "n_bins = 23\n",
    "window_size = 1000\n",
    "T = 100*window_size\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "stim_SD = 50\n",
    "max_L = 1.1\n",
    "\n",
    "stimuli = rng.laplace(0, stim_SD, size=T)\n",
    "# print(stimulus_entropy)\n",
    "\n",
    "\n",
    "lambda_idx = 4\n",
    "bias = 0\n",
    "response_bins = np.linspace(0, max_L, n_bins)\n",
    "\n",
    "moving_entropy_arr_stat_mov = np.zeros((len(orientation_arr), len(phase_arr), len(position_arr), len(wavelength_arr), int(T//window_size)))\n",
    "moving_entropy_arr_mov_stat = np.zeros((len(orientation_arr), len(phase_arr), len(position_arr), len(wavelength_arr), int(T//window_size)))\n",
    "moving_mean_arr_stat_mov = np.zeros((len(orientation_arr), len(phase_arr), len(position_arr), len(wavelength_arr), int(T//window_size)))\n",
    "moving_mean_arr_mov_stat = np.zeros((len(orientation_arr), len(phase_arr), len(position_arr), len(wavelength_arr), int(T//window_size)))\n",
    "responses_moving = np.zeros((len(orientation_arr), len(phase_arr), len(position_arr), len(wavelength_arr), T))\n",
    "responses_stationary = np.zeros((len(orientation_arr), len(phase_arr), len(position_arr), len(wavelength_arr), T))\n",
    "for i, ori in tqdm(enumerate(orientation_arr)):\n",
    "    for j, phase in enumerate(phase_arr):\n",
    "        for l, pos in enumerate(position_arr):\n",
    "            for m, wavelength in enumerate(wavelength_arr):\n",
    "                ori_idx = i\n",
    "                phase_idx = j\n",
    "                pos_idx = l\n",
    "                freq_idx = m\n",
    "                slope_stationary = optimal_k_arr_stationary[ori_idx, phase_idx, freq_idx, pos_idx, lambda_idx]\n",
    "                max_L_stationary = optimal_L_arr_stationary[ori_idx, phase_idx, freq_idx, pos_idx, lambda_idx]\n",
    "                slope_moving = optimal_k_arr_moving[ori_idx, phase_idx, freq_idx, pos_idx, lambda_idx]\n",
    "                max_L_moving = optimal_L_arr_moving[ori_idx, phase_idx, freq_idx, pos_idx, lambda_idx]\n",
    "\n",
    "                stationary_response = logistic_func(stimuli, k=slope_stationary, L=max_L_stationary, s_0=bias)\n",
    "                moving_response = logistic_func(stimuli, k=slope_moving, L=max_L_moving, s_0=bias)\n",
    "\n",
    "                responses_stationary[i, j, l, m, :] = stationary_response\n",
    "                responses_moving[i, j, l, m, :] = moving_response\n",
    "\n",
    "                # total_responses_stat_mov = np.concatenate((stationary_response[:T//2], moving_response[T//2:]))\n",
    "                # total_responses_mov_stat = np.concatenate((moving_response[:T//2], stationary_response[T//2:]))\n",
    "                # moving_entropy_stat_mov, moving_mean_stat_mov = calc_moving_entropy_mean(total_responses_stat_mov, response_bins, window_size)\n",
    "                # moving_entropy_mov_stat, moving_mean_mov_stat = calc_moving_entropy_mean(total_responses_mov_stat, response_bins, window_size)\n",
    "                # # moving_MI = calc_moving_MI(stimuli, total_responses, np.linspace(-3*stim_SD, 3*stim_SD, n_bins), np.linspace(0, max_L, n_bins), window_size)[:-window_size]\n",
    "                # moving_entropy_arr_stat_mov[i, j, l, m] = moving_entropy_stat_mov\n",
    "                # moving_entropy_arr_mov_stat[i, j, l, m] = moving_entropy_mov_stat\n",
    "                # moving_mean_arr_stat_mov[i, j, l, m] = moving_mean_stat_mov\n",
    "                # moving_mean_arr_mov_stat[i, j, l, m] = moving_mean_mov_stat\n",
    "                # moving_MI_arr[i, j, l, m] = moving_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_moving_mean_stat_mov = np.mean(moving_mean_arr_stat_mov, axis=(0, 1, 2, 3))\n",
    "avg_moving_mean_mov_stat = np.mean(moving_mean_arr_mov_stat, axis=(0, 1, 2, 3))\n",
    "avg_moving_entropy_stat_mov = np.mean(moving_entropy_arr_stat_mov, axis=(0, 1, 2, 3))\n",
    "avg_moving_entropy_mov_stat = np.mean(moving_entropy_arr_mov_stat, axis=(0, 1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_moving_mean_stat_mov)\n",
    "plt.plot(avg_moving_entropy_stat_mov)\n",
    "plt.plot(avg_moving_mean_mov_stat)\n",
    "plt.plot(avg_moving_entropy_mov_stat)\n",
    "# plt.plot(avg_moving_MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9a759-f85c-4181-afa8-c1d55ed1bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "ax_right = ax.twinx()\n",
    "\n",
    "x_ticks = np.arange(1, 101, 1)\n",
    "\n",
    "stimulus_entropy = calc_entropy(stimuli, np.linspace(-3*stim_SD, 3*stim_SD, n_bins))\n",
    "\n",
    "ax.vlines(T//(2*window_size), .15, .3, color='k', linestyle=':')\n",
    "ax.plot(x_ticks, avg_moving_mean_stat_mov, color='tab:blue', linewidth=2)\n",
    "ax.set_xticks([1, 50, 100])\n",
    "ax_right.plot(x_ticks, 1 - avg_moving_entropy_stat_mov/stimulus_entropy, color='tab:red', linewidth=2)\n",
    "# ax_right.set_ylim(0, 0.475)\n",
    "# ax.set_ylim(0, 0.3)\n",
    "ax.set_xlabel('Timesteps')\n",
    "ax.set_ylabel('Mean response')\n",
    "ax_right.set_ylabel('$1-I_{norm}$')\n",
    "plt.savefig('../cosyne_2025_figures/mineault_sim_stat_to_mov.pdf', bbox_inches='tight', format='pdf')\n",
    "# ax.set_xlim(40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth the responses and entropies with a boxcar filter\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "ax_right = ax.twinx()\n",
    "\n",
    "stimulus_entropy = calc_entropy(stimuli, np.linspace(-3*stim_SD, 3*stim_SD, n_bins))\n",
    "smooth_size = 10 # must be even\n",
    "x_ticks = np.arange(1, 101, 1)\n",
    "print(x_ticks.shape)\n",
    "print(bn.move_mean(avg_moving_mean_stat_mov, window=smooth_size).shape)\n",
    "\n",
    "\n",
    "ax.vlines(len(x_ticks)//2, 0, .3, color='k', linestyle=':')\n",
    "ax.plot(x_ticks[smooth_size//2:-smooth_size//2], bn.move_mean(avg_moving_mean_stat_mov, window=smooth_size)[smooth_size:], color='tab:blue', linewidth=2)\n",
    "ax.set_xticks([smooth_size//2, 50, 100-smooth_size//2])\n",
    "ax_right.plot(x_ticks[smooth_size//2:-smooth_size//2], bn.move_mean(1 - avg_moving_entropy_stat_mov/stimulus_entropy, window=smooth_size)[smooth_size:], color='tab:red', linewidth=2)\n",
    "ax_right.set_ylim(0, 0.475)\n",
    "ax.set_ylim(0, 0.3)\n",
    "ax.set_xlabel('Timesteps')\n",
    "ax.set_ylabel('Mean response')\n",
    "ax_right.set_ylabel('$1-I_{norm}$')\n",
    "plt.savefig('../cosyne_2025_figures/mineault_sim_stat_to_mov_smoothed.pdf', bbox_inches='tight', format='pdf')\n",
    "# ax.set_xlim(40, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "# smooth the responses and entropies with a boxcar filter\n",
    "cm= 1/2.54\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10*cm, 6*cm))\n",
    "\n",
    "ax_right = ax.twinx()\n",
    "\n",
    "stimulus_entropy = calc_entropy(stimuli, np.linspace(-3*stim_SD, 3*stim_SD, n_bins))\n",
    "sigma = 2 # size of Gaussian filter\n",
    "x_ticks = np.arange(1, 101, 1)\n",
    "\n",
    "\n",
    "ax.plot(x_ticks, gaussian_filter(avg_moving_mean_stat_mov, sigma=sigma), color='k', linewidth=2)\n",
    "ax.set_xticks([1, 50, 100])\n",
    "ax_right.plot(x_ticks, gaussian_filter(1 - avg_moving_entropy_stat_mov/stimulus_entropy, sigma=sigma), color='tab:blue', linewidth=2)\n",
    "ax.vlines(len(x_ticks)//2+0.5, 0.1, 0.3, color='k', linestyle=':')\n",
    "# ax_right.set_ylim(0, 0.475)\n",
    "ax.set_ylim(0.1, 0.3)\n",
    "ax.set_xlim(1, 100)\n",
    "ax_right.set_ylim(0.2,0.4)\n",
    "# ax.set_yticks([0.14, 0.28])\n",
    "# ax_right.set_yticks([0.25, 0.4])\n",
    "# ax.set_xlabel('Timesteps')\n",
    "# ax.set_ylabel('firing rate')\n",
    "# ax_right.set_ylabel('$1-I_{norm}$')\n",
    "# plt.savefig('../cosyne_2025_figures/mineault_sim_stat_to_mov_gauss_smoothed.svg', bbox_inches='tight', format='svg')\n",
    "plt.savefig('../manuscript_figures/fig2_mineault_sim_stat_to_mov_gauss_smoothed.pdf', bbox_inches='tight', format='pdf')\n",
    "# ax.set_xlim(40, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434300fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "# smooth the responses and entropies with a boxcar filter\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "ax_right = ax.twinx()\n",
    "\n",
    "stimulus_entropy = calc_entropy(stimuli, np.linspace(-3*stim_SD, 3*stim_SD, n_bins))\n",
    "sigma = 10 # size of Gaussian filter\n",
    "x_ticks = np.arange(1, 101, 1)\n",
    "\n",
    "\n",
    "ax.vlines(len(x_ticks)//2, 0, .3, color='k', linestyle=':')\n",
    "ax.plot(x_ticks, gaussian_filter(avg_moving_mean_mov_stat, sigma=sigma), color='tab:blue', linewidth=2)\n",
    "ax.set_xticks([1, 50, 100])\n",
    "ax_right.plot(x_ticks, gaussian_filter(1 - avg_moving_entropy_mov_stat/stimulus_entropy, sigma=sigma), color='tab:red', linewidth=2)\n",
    "ax_right.set_ylim(0, 0.475)\n",
    "ax.set_ylim(0, 0.3)\n",
    "ax.set_xlabel('Timesteps')\n",
    "ax.set_ylabel('Mean response')\n",
    "ax_right.set_ylabel('$1-I_{norm}$')\n",
    "plt.savefig('../manuscript_figures/mineault_sim_mov_to_stat_gauss_smoothed.pdf', bbox_inches='tight', format='pdf')\n",
    "# ax.set_xlim(40, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52347781",
   "metadata": {},
   "source": [
    "# Linear decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear decoder to predict the stimuli based on the response\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_input = responses_stationary.reshape(-1, T).T\n",
    "moving_input = responses_moving.reshape(-1, T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c336e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e41498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train regression\n",
    "stationary_regressor = LinearRegression()\n",
    "stationary_regressor.fit(stationary_input[:50000], stimuli[:50000])\n",
    "\n",
    "moving_regressor = LinearRegression()\n",
    "moving_regressor.fit(moving_input[:50000], stimuli[:50000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96716682",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_regressor.score(stationary_input, stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_regressor.score(moving_input, stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the decoder error for each sample as the rms\n",
    "stationary_decoder_error = (stationary_regressor.predict(stationary_input) - stimuli)**2\n",
    "moving_decoder_error = (moving_regressor.predict(moving_input) - stimuli)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dccfe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_decoder_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635349ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk the data and compute the mean decoder error for each chunk\n",
    "stationary_decoder_error = stationary_decoder_error.reshape(-1, window_size, T//(window_size)).mean(axis=1)\n",
    "moving_decoder_error = moving_decoder_error.reshape(-1, window_size, T//(window_size)).mean(axis=1)\n",
    "\n",
    "# take the sqrt\n",
    "stationary_decoder_error = np.sqrt(stationary_decoder_error)\n",
    "moving_decoder_error = np.sqrt(moving_decoder_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_decoder_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f604804",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stationary_decoder_error[0], label='stationary decoder error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moving_decoder_error[0], label='moving decoder error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255aff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to keep the last dimension the same but split the first dimension into two of size window_size\n",
    "stationary_input_reshape = stationary_input[:50000, :].T.reshape(-1, window_size, T//(2*window_size))\n",
    "moving_input_reshape = moving_input[:50000, :].T.reshape(-1, window_size, T//(2*window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_moving_mean_mov = np.nanmean(moving_input_reshape, axis=(0, 1))\n",
    "avg_moving_mean_stat = np.nanmean(stationary_input_reshape, axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "# smooth the responses and entropies with a boxcar filter\n",
    "cm= 1/2.54\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10*cm, 6*cm))\n",
    "\n",
    "ax_right = ax.twinx()\n",
    "\n",
    "sigma = 3 # size of Gaussian filter\n",
    "x_ticks = np.arange(1, 51, 1)\n",
    "\n",
    "\n",
    "ax.plot(x_ticks, gaussian_filter(np.concatenate([avg_moving_mean_stat[:25], avg_moving_mean_mov[25:]]), sigma=sigma), color='k', linewidth=2)\n",
    "ax.set_xticks([1, 50])\n",
    "ax_right.plot(x_ticks, gaussian_filter(np.concatenate([stationary_decoder_error[0, :25], moving_decoder_error[0, 25:50]]), sigma=sigma), color='tab:blue', linewidth=2)\n",
    "ax.vlines(len(x_ticks)//2, 0.1, 0.3, color='k', linestyle=':')\n",
    "ax.set_ylim(0.14, 0.3)\n",
    "ax.set_xlim(1, 50)\n",
    "# ax_right.set_ylim(0,0.14)\n",
    "\n",
    "# ax_right.set_ylim(0, 0.475)\n",
    "# ax.set_yticks([0.14, 0.28])\n",
    "# ax_right.set_yticks([0.25, 0.4])\n",
    "# ax.set_xlabel('Timesteps')\n",
    "# ax.set_ylabel('firing rate')\n",
    "# ax_right.set_ylabel('$1-I_{norm}$')\n",
    "# plt.savefig('../cosyne_2025_figures/mineault_sim_stat_to_mov_gauss_smoothed.svg', bbox_inches='tight', format='svg')\n",
    "plt.savefig('../manuscript_figures/fig2_mineault_sim_stat_to_mov_gauss_smoothed_decoder.pdf', bbox_inches='tight', format='pdf')\n",
    "# ax.set_xlim(40, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78570f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lococoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
