{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook loads and analyzes natural video data processed with Gabor filters at three different walking speeds.\n",
    "Date: 04.11.2024\n",
    "Author: Jonathan Gant\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from utilities import logistic_func, calc_MI, calc_entropy\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import bottleneck as bn\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# load in the data\n",
    "many_speeds_gabor_responses = h5py.File('../results/nat_videos_multi_speed_gabor_responses_full_res_more_low_freq_z_score.h5', 'r')\n",
    "all_gabor_responses = h5py.File('../results/new_nat_videos_gabor_responses_full_res_more_low_freq_z_score.h5', 'r')\n",
    "\n",
    "# video size\n",
    "resolution_height = 1080\n",
    "resolution_width = 1920\n",
    "\n",
    "# fov\n",
    "horizontal_fov = 92\n",
    "vertical_fov = 61\n",
    "\n",
    "# conversion factor of pixels to degrees\n",
    "horizontal_pixels_per_degree = resolution_width / horizontal_fov\n",
    "vertical_pixels_per_degree = resolution_height / vertical_fov\n",
    "\n",
    "# average of the conversion factors to the nearest integer\n",
    "pixels_per_degree = np.ceil((horizontal_pixels_per_degree + vertical_pixels_per_degree) / 2)\n",
    "print(pixels_per_degree)\n",
    "\n",
    "# data hyperparameters\n",
    "orientation_arr = all_gabor_responses['orientation_arr'][()]\n",
    "phase_arr = all_gabor_responses['phase_arr'][()]\n",
    "position_arr = all_gabor_responses['position_arr'][()]\n",
    "wavelength_arr = all_gabor_responses['wavelength_arr'][()]\n",
    "freq_arr = pixels_per_degree / wavelength_arr\n",
    "filter_size = (resolution_height, resolution_width)\n",
    "print(freq_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = ['field', 'forest', 'orchard']\n",
    "\n",
    "stationary_stim = []\n",
    "slow_stim = []\n",
    "medium_stim = []\n",
    "fast_stim = []\n",
    "\n",
    "# get the responses for each environment\n",
    "for env_key in environments:\n",
    "    all_gabor_responses_env = all_gabor_responses[env_key]\n",
    "    print(all_gabor_responses_env.keys())\n",
    "    for vid_key in all_gabor_responses_env.keys():\n",
    "        if 'stationary' in vid_key:\n",
    "            stationary_stim.append(all_gabor_responses_env[vid_key][()])\n",
    "    many_speeds_gabor_responses_env = many_speeds_gabor_responses[env_key]\n",
    "    for vid_key in many_speeds_gabor_responses_env.keys():\n",
    "        if 'slow' in vid_key:\n",
    "            slow_stim.append(many_speeds_gabor_responses_env[vid_key][()])\n",
    "        if 'medium' in vid_key:\n",
    "            medium_stim.append(many_speeds_gabor_responses_env[vid_key][()])\n",
    "        if 'fast' in vid_key:\n",
    "            fast_stim.append(many_speeds_gabor_responses_env[vid_key][()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stationary_stim)-1):\n",
    "    stationary_stim_arr = np.concatenate((stationary_stim[i], stationary_stim[i+1]), axis=-1)\n",
    "for i in range(len(slow_stim)-1):\n",
    "    slow_stim_arr = np.concatenate((slow_stim[i], slow_stim[i+1]), axis=-1)\n",
    "for i in range(len(medium_stim)-1):\n",
    "    medium_stim_arr = np.concatenate((medium_stim[i], medium_stim[i+1]), axis=-1)\n",
    "for i in range(len(fast_stim)-1):\n",
    "    fast_stim_arr = np.concatenate((fast_stim[i], fast_stim[i+1]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the moving SD of each of the stimuli\n",
    "\n",
    "import bottleneck as bn\n",
    "\n",
    "fps = 30\n",
    "window_length = 5 # seconds\n",
    "window_size = int(window_length * fps)\n",
    "\n",
    "windowed_std_stationary_responses = bn.move_std(stationary_stim_arr, window=window_size, min_count=window_size, axis=-1)\n",
    "windowed_std_slow_responses = bn.move_std(slow_stim_arr, window=window_size, min_count=window_size, axis=-1)\n",
    "windowed_std_medium_responses = bn.move_std(medium_stim_arr, window=window_size, min_count=window_size, axis=-1)\n",
    "windowed_std_fast_responses = bn.move_std(fast_stim_arr, window=window_size, min_count=window_size, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_std_slow_responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nanmean(windowed_std_slow_responses[3, 1, 2, 4, :]))\n",
    "print(np.nanmean(windowed_std_medium_responses[3, 1, 2, 4, :]))\n",
    "print(np.nanmean(windowed_std_fast_responses[3, 1, 2, 4, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize nonlinearities using lookup table\n",
    "dir_name = 'gaussian_optimization_analytic_fast' # 'all_sigma_more_bins_zscored_data'# 'higher_sigma_for_zscored_data' # 'more_sigma_bins_gaussian_results' # 'even_more_sigma_bins_gaussian_results'\n",
    "\n",
    "MI_arr = np.load(dir_name + '/MI_arr.npy')\n",
    "# stimulus_entropy = np.load(dir_name + '/stimulus_entropy.npy')\n",
    "average_response_arr = np.load(dir_name + '/average_response_arr.npy')\n",
    "\n",
    "# stimulus_bins = np.load(dir_name + '/stimulus_bins.npy') # np.linspace(-30, 30, 200)\n",
    "\n",
    "# Define the range of k and L values for grid search\n",
    "k_arr = np.load(dir_name + '/k_arr.npy') # np.logspace(-2, 2, num_bins) # 5*np.logspace(-2, 0, 100)\n",
    "L_arr = np.load(dir_name + '/L_arr.npy') # np.arange(0.02, 4.02, .02) # np.arange(0.05, 5.05, .05)\n",
    "sigma_arr = np.load(dir_name + '/sigma_arr.npy') # 5*np.logspace(-2, 1, num_bins) # np.logspace(-2, 2, num_bins)\n",
    "\n",
    "# for each sigma compute the optimal parameters for a range of different lambdas\n",
    "lambda_arr = np.arange(0, 2.25, 0.25)\n",
    "optimal_k = np.zeros((len(sigma_arr), len(lambda_arr)))\n",
    "optimal_L = np.zeros((len(sigma_arr), len(lambda_arr)))\n",
    "\n",
    "# import gaussian filter to involve\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "for i, lambda_ in enumerate(lambda_arr):\n",
    "    utility = MI_arr - lambda_ * average_response_arr\n",
    "    print(utility.shape)\n",
    "    # utility = gaussian_filter(utility, sigma=4, axes=(1, 2))\n",
    "    for j, sigma in enumerate(sigma_arr):\n",
    "        optimal_k[j, i] = k_arr[np.unravel_index(np.argmax(utility[j, :, :]), utility[j, :, :].shape)[0]]\n",
    "        optimal_L[j, i] = L_arr[np.unravel_index(np.argmax(utility[j, :, :]), utility[j, :, :].shape)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all orientations and phases and wavelengths and compute the optimal parameters for each\n",
    "optimal_k_arr_stationary = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_L_arr_stationary = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_k_arr_slow = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_L_arr_slow = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_k_arr_medium = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_L_arr_medium = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_k_arr_fast = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "optimal_L_arr_fast = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), len(lambda_arr)))\n",
    "\n",
    "for i, orientation in tqdm(enumerate(orientation_arr)):\n",
    "    print(\"orientation: \" + str(orientation))\n",
    "    for j, phase in enumerate(phase_arr):\n",
    "        for l, wavelength in enumerate(wavelength_arr):\n",
    "            for m, position in enumerate(position_arr):\n",
    "                test_stationary_std = np.nanmean(windowed_std_stationary_responses[i, j, l, m, :], axis=-1)\n",
    "                test_slow_std = np.nanmean(windowed_std_slow_responses[i, j, l, m, :], axis=-1)\n",
    "                test_medium_std = np.nanmean(windowed_std_medium_responses[i, j, l, m, :], axis=-1)\n",
    "                test_fast_std = np.nanmean(windowed_std_fast_responses[i, j, l, m, :], axis=-1)\n",
    "                for n, lambda_ in enumerate(lambda_arr):\n",
    "                    stationary_idx = np.argmin(np.abs(sigma_arr - test_stationary_std))\n",
    "                    optimal_k_arr_stationary[i, j, l, m, n] = optimal_k[stationary_idx, n]\n",
    "                    optimal_L_arr_stationary[i, j, l, m, n] = optimal_L[stationary_idx, n]\n",
    "                    slow_idx = np.argmin(np.abs(sigma_arr - test_slow_std))\n",
    "                    optimal_k_arr_slow[i, j, l, m, n] = optimal_k[slow_idx, n]\n",
    "                    optimal_L_arr_slow[i, j, l, m, n] = optimal_L[slow_idx, n]\n",
    "                    medium_idx = np.argmin(np.abs(sigma_arr - test_medium_std))\n",
    "                    optimal_k_arr_medium[i, j, l, m, n] = optimal_k[medium_idx, n]\n",
    "                    optimal_L_arr_medium[i, j, l, m, n] = optimal_L[medium_idx, n]\n",
    "                    fast_idx = np.argmin(np.abs(sigma_arr - test_fast_std))\n",
    "                    optimal_k_arr_fast[i, j, l, m, n] = optimal_k[fast_idx, n]\n",
    "                    optimal_L_arr_fast[i, j, l, m, n] = optimal_L[fast_idx, n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationary_std = np.nanmean(windowed_std_stationary_responses, axis=(0, 1, 3, 4))\n",
    "test_slow_std = np.nanmean(windowed_std_slow_responses, axis=(0, 1, 3, 4))\n",
    "test_medium_std = np.nanmean(windowed_std_medium_responses, axis=(0, 1, 3, 4))\n",
    "test_fast_std = np.nanmean(windowed_std_fast_responses, axis=(0, 1, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fast_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds = [0, 1000/45, 1000/30, 1000/20]\n",
    "# for freq_idx in range(10):\n",
    "    # plt.plot(speeds, [1, test_slow_std[freq_idx]/test_stationary_std[freq_idx], test_medium_std[freq_idx]/test_stationary_std[freq_idx], test_fast_std[freq_idx]/test_stationary_std[freq_idx]], 'o-')\n",
    "plt.plot(np.arange(len(freq_arr)), test_fast_std/test_stationary_std, 'o-')\n",
    "plt.plot(np.arange(len(freq_arr)), test_medium_std/test_stationary_std, 'o-')\n",
    "plt.plot(np.arange(len(freq_arr)), test_slow_std/test_stationary_std, 'o-')\n",
    "plt.xticks(np.arange(len(freq_arr)), freq_arr)\n",
    "# plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.hlines(1, 0, len(freq_arr)-1, 'k', '--')\n",
    "# plt.ylim(.9, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the responses of the optimal nonlinearities for each speed\n",
    "\n",
    "num_samples = 10000\n",
    "test_stimuli = np.random.laplace(0, 10, num_samples)\n",
    "\n",
    "lambda_idx = 4\n",
    "\n",
    "fast_responses = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), num_samples))\n",
    "medium_responses = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), num_samples))\n",
    "slow_responses = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), num_samples))\n",
    "stationary_responses = np.zeros((len(orientation_arr), len(phase_arr), len(wavelength_arr), len(position_arr), num_samples))\n",
    "\n",
    "for i, ori in enumerate(orientation_arr):\n",
    "    for j, phase in enumerate(phase_arr):\n",
    "        for k, freq in enumerate(freq_arr):\n",
    "            for l, pos in enumerate(position_arr):\n",
    "                # compute responses for each speed\n",
    "                fast_responses[i, j, k, l] = logistic_func(test_stimuli, k=optimal_k_arr_fast[i, j, k, l, lambda_idx], L=optimal_L_arr_fast[i, j, k, l, lambda_idx])\n",
    "                medium_responses[i, j, k, l] = logistic_func(test_stimuli, k=optimal_k_arr_medium[i, j, k, l, lambda_idx], L=optimal_L_arr_medium[i, j, k, l, lambda_idx])\n",
    "                slow_responses[i, j, k, l] = logistic_func(test_stimuli, k=optimal_k_arr_slow[i, j, k, l, lambda_idx], L=optimal_L_arr_slow[i, j, k, l, lambda_idx])\n",
    "                stationary_responses[i, j, k, l] = logistic_func(test_stimuli, k=optimal_k_arr_stationary[i, j, k, l, lambda_idx], L=optimal_L_arr_stationary[i, j, k, l, lambda_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_arr[lambda_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fast_responses_per_filter = np.mean(fast_responses[:, :, :, :, :], axis=-1)\n",
    "avg_medium_responses_per_filter = np.mean(medium_responses[:, :, :, :, :], axis=-1)\n",
    "avg_slow_responses_per_filter = np.mean(slow_responses[:, :, :, :, :], axis=-1)\n",
    "avg_stationary_responses_per_filter = np.mean(stationary_responses[:, :, :, :, :], axis=-1)\n",
    "num_filters = len(avg_stationary_responses_per_filter.flatten())\n",
    "\n",
    "# compute the average responses for each speed\n",
    "avg_fast_responses = np.mean(avg_fast_responses_per_filter)\n",
    "avg_medium_responses = np.mean(avg_medium_responses_per_filter)\n",
    "avg_slow_responses = np.mean(avg_slow_responses_per_filter)\n",
    "avg_stationary_responses = np.mean(avg_stationary_responses_per_filter)\n",
    "\n",
    "# compute the SD\n",
    "std_fast_responses = np.std(avg_fast_responses_per_filter)\n",
    "std_medium_responses = np.std(avg_medium_responses_per_filter)\n",
    "std_slow_responses = np.std(avg_slow_responses_per_filter)\n",
    "std_stationary_responses = np.std(avg_stationary_responses_per_filter)\n",
    "\n",
    "speeds = np.array([0, 1000/45, 1000/30, 1000/20])\n",
    "avg_responses = [avg_stationary_responses, avg_slow_responses, avg_medium_responses, avg_fast_responses]\n",
    "std_responses = [std_stationary_responses, std_slow_responses, std_medium_responses, std_fast_responses]\n",
    "\n",
    "plt.plot(speeds, avg_responses) # \n",
    "# plt.fill_between(speeds, np.array(avg_responses) - np.array(std_responses), np.array(avg_responses) + np.array(std_responses), alpha=0.2)\n",
    "plt.xlabel('Speed (cm/s)')\n",
    "plt.ylabel('Average Response')\n",
    "\n",
    "# fit an exponential function to the responses\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def exponential_func(x, a, b, c):\n",
    "    return a-c*np.exp(b * x)\n",
    "\n",
    "# format all data per filter to be fit\n",
    "speeds = [[0]*num_filters, [1000/45]*num_filters, [1000/30]*num_filters, [1000/20]*num_filters]\n",
    "speeds = np.array(speeds).flatten()\n",
    "avg_responses = np.concatenate((avg_stationary_responses_per_filter.flatten(), avg_slow_responses_per_filter.flatten(), avg_medium_responses_per_filter.flatten(), avg_fast_responses_per_filter.flatten()))\n",
    "\n",
    "popt, pcov = curve_fit(exponential_func, speeds, avg_responses, p0=[.9, -.01, .3], maxfev=int(1e6), ftol=1e-8)\n",
    "\n",
    "plt.plot(np.linspace(0, 50, 200), exponential_func(np.linspace(0, 50, 200), *popt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_sigma_x = .5\n",
    "jitter_sigma_y = .01\n",
    "num_filters = len(avg_stationary_responses_per_filter.flatten())\n",
    "plt.scatter([0]*num_filters+np.random.normal(0, jitter_sigma_x, num_filters), avg_stationary_responses_per_filter.flatten()+np.random.normal(0, jitter_sigma_y, num_filters), s=10, color='tab:red', label='stationary', edgecolor='w', linewidth=.2)\n",
    "plt.scatter([1000/45]*num_filters+np.random.normal(0, jitter_sigma_x, num_filters), avg_slow_responses_per_filter.flatten()+np.random.normal(0, jitter_sigma_y, num_filters), s=10, color='tab:pink', label='slow', edgecolor='w', linewidth=.2)\n",
    "plt.scatter([1000/30]*num_filters+np.random.normal(0, jitter_sigma_x, num_filters), avg_medium_responses_per_filter.flatten()+np.random.normal(0, jitter_sigma_y, num_filters), s=10, color='tab:purple', label='medium', edgecolor='w', linewidth=.2)\n",
    "plt.scatter([1000/20]*num_filters+np.random.normal(0, jitter_sigma_x, num_filters), avg_fast_responses_per_filter.flatten()+np.random.normal(0, jitter_sigma_y, num_filters), s=10, color='tab:blue', label='fast', edgecolor='w', linewidth=.2)\n",
    "plt.plot(np.linspace(0, 50, 200), exponential_func(np.linspace(0, 50, 200), *popt), color='k', linewidth=2)\n",
    "plt.xlabel('Speed (cm/s)')\n",
    "plt.ylabel('Average Response')\n",
    "plt.legend()\n",
    "plt.savefig('../manuscript_figures/speed_tuning.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds = np.round(np.array([0, 1000/45, 1000/30, 1000/20])).astype(int)\n",
    "colors = ['tab:red', 'tab:pink', 'tab:purple', 'tab:blue']\n",
    "bplot = plt.boxplot([avg_stationary_responses_per_filter.flatten(), avg_slow_responses_per_filter.flatten(), avg_medium_responses_per_filter.flatten(), avg_fast_responses_per_filter.flatten()], positions=speeds, showfliers=False, patch_artist=True, widths=5, medianprops={'color': 'k', 'linewidth': 2})\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "plt.plot(np.linspace(0, 50, 200), exponential_func(np.linspace(0, 50, 200), *popt), color='k', linewidth=2)\n",
    "plt.xlabel('Speed (cm/s)')\n",
    "plt.ylabel('Average Response')\n",
    "# plt.legend()\n",
    "plt.savefig('../manuscript_figures/speed_tuning_box_plot.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax2.errorbar(high_freq_bins, high_freq_median, yerr=[high_freq_median - high_freq_25th, high_freq_75th - high_freq_median], color='tab:pink', ecolor='k', capsize=5, linestyle='', fmt='o')\n",
    "\n",
    "stationary_median = np.median(avg_stationary_responses_per_filter.flatten())\n",
    "stationary_mean = np.mean(avg_stationary_responses_per_filter.flatten())\n",
    "slow_median = np.median(avg_slow_responses_per_filter.flatten())\n",
    "slow_mean = np.mean(avg_slow_responses_per_filter.flatten())\n",
    "medium_median = np.median(avg_medium_responses_per_filter.flatten())\n",
    "medium_mean = np.mean(avg_medium_responses_per_filter.flatten())\n",
    "fast_median = np.median(avg_fast_responses_per_filter.flatten())\n",
    "fast_mean = np.mean(avg_fast_responses_per_filter.flatten())\n",
    "stationary_25th = np.percentile(avg_stationary_responses_per_filter.flatten(), 25)\n",
    "stationary_75th = np.percentile(avg_stationary_responses_per_filter.flatten(), 75)\n",
    "slow_25th = np.percentile(avg_slow_responses_per_filter.flatten(), 25)\n",
    "slow_75th = np.percentile(avg_slow_responses_per_filter.flatten(), 75)\n",
    "medium_25th = np.percentile(avg_medium_responses_per_filter.flatten(), 25)\n",
    "medium_75th = np.percentile(avg_medium_responses_per_filter.flatten(), 75)\n",
    "fast_25th = np.percentile(avg_fast_responses_per_filter.flatten(), 25)\n",
    "fast_75th = np.percentile(avg_fast_responses_per_filter.flatten(), 75)\n",
    "stationary_sd = np.std(avg_stationary_responses_per_filter.flatten())\n",
    "slow_sd = np.std(avg_slow_responses_per_filter.flatten())\n",
    "medium_sd = np.std(avg_medium_responses_per_filter.flatten())\n",
    "fast_sd = np.std(avg_fast_responses_per_filter.flatten())\n",
    "\n",
    "median_responses = np.array([stationary_median, slow_median, medium_median, fast_median])\n",
    "mean_responses = np.array([stationary_mean, slow_mean, medium_mean, fast_mean])\n",
    "response_sd = np.array([stationary_sd, slow_sd, medium_sd, fast_sd])\n",
    "responses_25th = np.array([stationary_25th, slow_25th, medium_25th, fast_25th])\n",
    "responses_75th = np.array([stationary_75th, slow_75th, medium_75th, fast_75th])\n",
    "\n",
    "speeds = np.round(np.array([0, 1000/45, 1000/30, 1000/20])).astype(int)\n",
    "colors = ['tab:red', 'tab:pink', 'tab:purple', 'tab:blue']\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16,6))\n",
    "for i in range(len(colors)):\n",
    "    ax[0].errorbar(speeds[i], median_responses[i], yerr=[[median_responses[i]-responses_25th[i]], [responses_75th[i]-median_responses[i]]], fmt='o', color=colors[i], capsize=5)\n",
    "    ax[1].errorbar(speeds[i], mean_responses[i], yerr=response_sd[i], fmt='o', color=colors[i], capsize=5)\n",
    "# plt.errorbar(speeds, median_responses, yerr=[median_responses-responses_25th, responses_75th-median_responses], fmt='o', color=colors, capsize=5)\n",
    "ax[0].plot(np.linspace(0, 50, 200), exponential_func(np.linspace(0, 50, 200), *popt), color='k', linewidth=2)\n",
    "ax[1].plot(np.linspace(0, 50, 200), exponential_func(np.linspace(0, 50, 200), *popt), color='k', linewidth=2)\n",
    "ax[0].set_xlabel('Speed (cm/s)')\n",
    "ax[1].set_xlabel('Speed (cm/s)')\n",
    "ax[0].set_ylabel('Average Response')\n",
    "ax[0].set_ylim(0,.35)\n",
    "ax[1].set_ylim(0,.45)\n",
    "ax[0].set_title('Median Response with quartiles')\n",
    "ax[1].set_title('Mean Response with SD')\n",
    "# plt.legend()\n",
    "plt.savefig('../manuscript_figures/speed_tuning_scatter_with_error.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the norm factor as the max for each speed\n",
    "norm_factor = np.max([np.max(avg_stationary_responses_per_filter), np.max(avg_slow_responses_per_filter), np.max(avg_medium_responses_per_filter), np.max(avg_fast_responses_per_filter)])\n",
    "norm_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1/2.54\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6*cm,6*cm))\n",
    "# plt.errorbar(speeds, median_responses, yerr=[median_responses-responses_25th, responses_75th-median_responses], fmt='o', color=colors, capsize=5)\n",
    "ax.plot(np.linspace(0, 50, 200), exponential_func(np.linspace(0, 50, 200), *popt)/norm_factor, color='k', linewidth=2)\n",
    "ax.plot(speeds, mean_responses/norm_factor, 'o')\n",
    "ax.set_xlabel('Speed (cm/s)')\n",
    "ax.set_ylabel('Norm response')\n",
    "ax.set_ylim(0, 0.5)\n",
    "# plt.legend()\n",
    "plt.savefig('../manuscript_figures/fig2_speed_tuning_fit.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
